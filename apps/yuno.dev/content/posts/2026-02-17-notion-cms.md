---
title: "Notion API를 활용한 CMS 구축"
date: "2025-02-17"
excerpt: "Notion을 콘텐츠 소스로 활용해 자체 렌더링 CMS를 구축한 과정과, 구현 중 마주친 문제들을 정리했다."
tags: ["Frontend", "Notion", "CMS", "AI"]
---

현재 회사 서비스 중 관리자 페이지에는 공지사항 외에 매장에 콘텐츠를 전달할 수 있는 경로가 없었다.

신규 기능 소개, 활용 사례, 트렌드 리포트 같은 콘텐츠를 매장에 전달하려면 새로운 지면이 필요했고,
이를 위해 다양한 콘텐츠를 게시할 수 있는 CMS를 구축하게 되었다.

자체 에디터를 구현하기엔 공수가 과하다고 판단해 외부 작성 툴을 활용하기로 했고,
운영팀이 이미 사용하고 있던 Notion이 선택되었다.

Notion Database로 게시물 메타데이터를 관리하고,  
페이지 본문이 곧 콘텐츠가 되는 구조로 별도의 백오피스 없이도 콘텐츠 관리가 가능하도록 했다.

이 글에서는 Notion API를 활용해 CMS를 구축한 과정을 공유하고자 한다.

## 기술 선정

Notion을 콘텐츠 소스로 결정한 뒤, 이를 어떻게 노출할지가 다음 문제였다.

노출 방식을 결정하기 전에 먼저 요구사항을 정리할 필요가 있었다.  
대부분의 요구사항이 콘텐츠 작성과 관련된 것이었고, Notion이 이미 모두 제공하고 있었기 때문에 별도 구현이 필요 없었다.  
하지만 핵심 요구사항 중 하나로, 페이지 내 링크가 삽입되었을 때 사용자가 어떤 링크를 클릭했는지 로그를 남겨야 한다는 것이 있었다.

가장 쉬운 방법 두 가지를 먼저 검토했지만 둘 다 이 핵심 요구사항을 충족하지 못했다.

어떤 매장이 어떤 콘텐츠의 어떤 링크를 클릭했는지 수준의 세분화된 로깅이 필요했다.
이를 구현하려면 렌더링되는 모든 요소를 직접 제어할 수 있어야 했다.

- iframe 임베딩: Notion 페이지를 iframe으로 띄우면 가장 간단하지만, UX 문제가 심각했다. 로딩 속도가 느리고, 페이지 내 스크롤과 iframe 스크롤이 이중화되며, 모바일/PC 반응형 대응이 어렵다.  
  무엇보다 iframe 내부가 노션이기 때문에 콘텐츠 내부 링크나 이미지에 클릭 로그를 심을 수 없다.

- [우피(Oopy)](https://www.oopy.io/): 노션 페이지를 웹사이트로 변환해주는 서비스로, 기존 캐치테이블 비즈니스 일부 페이지에서 이미 사용하고 있었다. GA 연동으로 page_view나 기본 클릭 로그는 남길 수 있지만, 콘텐츠 내부 요소(특정 링크, 이미지)에 커스텀 로그를 삽입할 수 있는 구조가 아니었다.

결국 Notion을 에디팅 도구로 활용하되,  
[Notion Public API](https://developers.notion.com/reference/intro)를 직접 호출해서 블록 데이터를 가져오고 자체 렌더링하는 방향으로 결정했다.

이렇게 하면 렌더링되는 모든 요소를 React 컴포넌트로 직접 제어할 수 있고,
링크나 이미지 클릭 시 원하는 로그를 자유롭게 삽입할 수 있다.

자체 렌더링을 하기로 큰 방향을 정한 뒤,  
세부적으로 어떻게 글을 가져올 것인지, 그리고 어떻게 글을 렌더링할 것인지 결정해야 했다.

### 데이터 호출: 클라이언트 vs 백엔드

Notion API를 누가 호출할 것인가? 클라이언트에서 직접 호출하는 방식도 가능했지만, 두 가지 이유로 백엔드에서 API를 바라보도록 했다.

첫째, 보안 문제다. Notion API 호출에는 Integration Token이 필요한데, 이를 클라이언트에서 가지고 있으면 보안 관련 위험이 있다고 판단했다.

둘째, 향후 자체 CMS 도입 가능성이다. 클라이언트가 Notion API에 직접 의존하면 나중에 교체 비용이 커진다. 백엔드가 중간에서 데이터를 전달하는 구조라면, 클라이언트는 Notion의 존재를 모르기 때문에 데이터소스 교체 시 프론트엔드 변경을 최소화할 수 있다.

자체 DB에 Notion 데이터를 동기화하는 방안도 논의했지만, 백엔드 공수가 늘어나고 Notion과 자체 DB 간 싱크를 지속적으로 맞춰야 하는 부담이 있었다.  
초기 버전에서 이 복잡도는 과했기에 우선 단순 바이패스로 시작했다.

### 렌더링: Markdown 변환 vs Notion UI 라이브러리

[화해 기술 블로그](https://blog.hwahae.co.kr/all/tech/10960)처럼 [notion-to-md](https://github.com/souvikinator/notion-to-md) 같은 패키지로 Notion 블록을 Markdown으로 변환한 뒤 렌더링하는 방법도 검토했다.  
추후 자체 CMS로 전환할 때 Markdown은 표준 포맷이라 유연하게 이관할 수 있다는 장점이 있었다.

하지만 아직 어떤 콘텐츠를 어떤 형태로 올릴지 정해지지 않은 상황이었다.  
Markdown으로 변환하는 과정에서 지원되지 않는 블록이 생길 수 있었고, 변환과 렌더링 두 단계가 추가되면서 일정과 복잡도가 늘어나는 것도 부담이었다.

우선 Notion의 블록 타입을 제한 없이 활용하고, 추후 사용 방식을 보고 따라 포맷을 결정하는 편이 낫다고 판단했다.  
Notion UI 컴포넌트 라이브러리를 사용하면 자체 CMS 도입 시 UI 컴포넌트만 교체하면 되니, 지금 단계에서 이 방향이 적절하다고 생각했다.

## 구현 과정에서 마주친 문제들

기술 선정을 마치고 구현에 들어가자 예상하지 못한 문제들이 연달아 발생했다.  
빠른 배포를 목표로 시작한 프로젝트였고 Notion API에 대한 이해가 부족한 상태에서 진행하다 보니,
기술 선정 단계에서 미처 고려하지 못했던 제약들이 하나씩 드러났다.

### 중첩 블록과 재귀적 API 호출

Notion API는 페이지의 블록을 조회할 때 1-depth만 반환한다. 리스트, 토글, 컬럼 같은 하위 블록이 있는 경우 `has_children: true`라는 속성만 내려올 뿐, 자식 블록의 실제 데이터는 [별도 API를 호출](https://developers.notion.com/reference/get-block-children)해서 가져와야 한다.

즉, 중첩이 깊은 콘텐츠라면 자식 블록을 재귀적으로 반복 호출해야 완전한 페이지 데이터를 확보할 수 있다.

이 구조를 클라이언트에서 처리하면 API 호출 로직이 복잡해지고, 페이지 하나를 렌더링하기 위해 수십 번의 네트워크 요청이 발생할 수 있다.  
결국 백엔드에서 필요한 모든 블록을 재귀적으로 호출한 뒤, 완성된 블록 트리를 클라이언트에 한 번에 내려주는 구조로 진행했다.

### 성능 문제와 캐싱 도입

그런데 백엔드에서 재귀적으로 블록을 모두 조회하고 [Notion API의 Request Limit](https://developers.notion.com/reference/request-limits)때문에 딜레이를 걸어두어서 응답 속도가 심각하게 느려졌다.

처음에는 바이패스만으로 충분하다고 판단했지만, 성능 문제 때문에 결국 백엔드에 캐싱 레이어를 추가하게 되었다.  
기술 선정 단계에서 자체 DB 동기화는 과하다고 넘겼던 부분이, 구현 단계에서 결국 필요해진 셈이다.

### UI 라이브러리의 API 불일치

렌더링을 위한 UI 라이브러리를 본격적으로 연동하려 하자 또 다른 문제가 발생했다.  
대부분의 Notion 렌더링 라이브러리(`react-notion-x`, `react-notion` 등)가 Unofficial API(비공식 내부 API)를 기반으로 설계되어 있었다.

이 라이브러리들이 기대하는 데이터 타입 스펙이 Public API 응답과 달랐고, 클라이언트에서 직접 Notion을 호출하는 것을 전제로 설계되어 있었다. 이미 백엔드 바이패스 구조를 선택한 상황에서 이런 라이브러리들은 사용할 수 없었다.

Public API 응답을 그대로 받아서 렌더링만 담당하는 라이브러리를 찾아야 했고, 그 조건에 맞는 유일한 라이브러리가 [react-notion-render(@9gustin)](https://github.com/9gustin/react-notion-render)였다.

`react-notion-render`는 Notion Public API 타입을 기반으로 UI 렌더링만 담당하는 순수한 구조였다.  
하지만 링크 클릭 시 커스텀 콜백을 주입할 수 없었다.

링크 클릭 로깅은 핵심 요구사항이었고, 외부 wrapper로는 해결이 불가능했다.
렌더러 내부의 Link/Image 컴포넌트를 직접 수정해야 했다.

결국 `@manager/notion-renderer`로 포크해 내부 패키지로 추가하기로 했다.
평소라면 쉽게 내리지 않았을 결정이지만, Claude Code가 있다면 유지보수 부담을 감당할 수 있다고 판단했다.

이 라이브러리는 Notion API의 고정된 JSON 스키마를 렌더링하는 단일 목적 패키지였다.
외부 의존성도 없고 스펙도 명확하니, AI가 맥락을 파악하기에 오히려 유리한 구조였다.

포크해서 개발하다 보니 라이브러리 상태가 예상보다 좋지 않았다.
테스트 중 버그가 꽤 발견됐고, 특정 블록 조합에서 렌더링이 되지 않아 신규 기능이 필요한 케이스도 있었다.

버그 분석과 수정, 신규 기능 추가, 각 케이스에 대한 테스트 작성까지 모든 작업을 Claude Code로 진행했다.
변경사항이 쌓일수록 추적이 필요해졌는데, CHANGELOG 작성까지 Claude Code에 맡겼다.

### 메타데이터 조회 문제

마지막으로 예상하지 못한 문제가 하나 더 있었다.  
Notion API로 페이지 블록을 조회하면 본문 내용만 반환되고, 제목/작성일/태그 같은 메타데이터는 포함되지 않는다.  
메타데이터는 Notion Database의 속성(property)으로 관리되기 때문에, 블록 조회와는 별도로 Database API를 호출해야만 가져올 수 있다.

목록 페이지에서 상세로 진입하는 경우는 이미 메타데이터를 전역 상태에 가지고 있어 그대로 사용하면 됐다.  
하지만 URL로 상세 페이지에 직접 진입하면 메타데이터가 없다.
이를 위해 상세 페이지에서 별도로 Database 목록 API를 호출해 해당 게시물의 메타데이터를 가져오는 방식으로 임시 처리했다.

근본적인 해결은 백엔드에 자체 DB를 두는 것이라, 점진적인 개선 과정에서 진행할 예정이다.

## 돌아보며

지금 돌아보면,
빠른 배포를 우선했던 탓에 Notion API에 대한 이해 부족으로 초기 방향성을 잘못 결정했던 것 같다.  
조금 더 쉽고 빠르게 개발하는 것만 생각해서 안정성이나 다른 부분은 고려하지 못했다.

처음부터 자체 DB를 구축했다면 이후에 추가된 백엔드 작업들을 진작에 고려할 수 있었을 것이고,
메타데이터 조회 문제도 발생하지 않았을 것이다.

Markdown 같은 표준 포맷으로 저장했다면 추후 자체 에디터를 도입하더라도 점진적인 이관이 가능했을 것이다.

Markdown을 렌더링하는 UI 라이브러리는 이미 충분히 성숙해 있어서 클라이언트 부담도 훨씬 적었을 것이다.
Markdown으로는 지원할 수 없는 블록 타입이 많지만, 필수적인 블록들을 선정해서
[Markdown을 확장](https://gist.github.com/vimtaai/99f8c89e7d3d02a362117284684baa0f)해서 자체 CMS로 표현 기능을 점진적으로 넓혀가는 방향이 더 안정적이었을 것 같다.

하지만 이미 결정을 내린 뒤에, 그 선택이 만들어낸 제약들을 하나씩 해소해 나가는 과정에도 나름의 의미가 있었다.

특히 Claude Code를 활용해 외부 라이브러리를 내부 패키지로 전환한 결정은 기존에는 쉽게 시도하지 않았을 방식이었다. 하지만 AI의 도움으로 부담이 낮아지면서 현실적인 선택지가 되었다.  
AI가 단순히 코드를 대신 작성해주는 도구라기보다, 시도해볼 수 있는 전략의 범위를 넓혀준 셈이다.

최근 Claude Code와 같은 AI를 업무 안팎에서 자주 활용하고 있다.  
이번 작업을 통해 느낀 점은, AI가 기능 구현을 빠르게 돕는 수준을 넘어 설계와 의사결정의 가능성을 확장해준다는 것이다.  
이전이라면 비용 대비 효용을 따져 포기했을 선택지도, 이제는 검토 가능한 대안이 된다. 그 변화가 작지 않게 다가왔다.
